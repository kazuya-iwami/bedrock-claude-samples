{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6925c-fcba-463c-b6fa-5c0808cb919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U pip\n",
    "%pip install -U botocore boto3\n",
    "%pip install boto3 anthropic langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85218a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5453aba5-7ebc-48f6-b346-fdccfc2fb2e5",
   "metadata": {},
   "source": [
    "## 以下のコマンドで最新のmoduleを利用していることを確認してください\n",
    "- boto3 >= 1.28.57\n",
    "- botocore >= 1.31.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99c305-6eb9-4429-b07c-cf363bab4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list | grep -E 'botocore|boto3' | awk '{print $1, $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31316e-80a9-44b6-a3cd-cd665d339a2c",
   "metadata": {},
   "source": [
    "## モデルを利用可能な状態に設定\n",
    "はじめてそのアカウント、リージョンでBedrockをご利用になる場合は、マネジメントコンソールのModel Accessページからモデルを利用可能にする設定が必要です。\n",
    "\n",
    "詳細はドキュメントをご確認ください。https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html#add-model-access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e6b10-1a41-4e06-a994-1c8eb67805b9",
   "metadata": {},
   "source": [
    "## シンプルなBedrockの利用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2f833c-1d02-4fd9-a40d-c5496f57f5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " はい、こんにちは。どうぞよろしくお願いします。\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrockでは、InvokeModelとInvokeModelWithStreamingResponse APIを呼び出す場合のみ \"bedrock-runtime\" を利用し、それ以外では\" bedrock\" を利用します。\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "text = \"こんにちは\"\n",
    "# Anthropic社のClaudeモデルでは、以下のようなフォーマットを利用するよう公式サイトに案内があります https://docs.anthropic.com/claude/docs/introduction-to-prompt-design#human--assistant-formatting\n",
    "# Bedrockではフォーマットに従わない場合エラーが返される挙動になっていますのでご注意下さい。\n",
    "prompt = f\"\\n\\nHuman: {text}\\n\\nAssistant:\"\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "        body=json.dumps({\"prompt\": prompt, \"max_tokens_to_sample\": 100}), modelId=\"anthropic.claude-v2\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body.get(\"completion\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438dfdab-19d1-44ce-922f-79ea7ea03266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon.titan-tg1-large\n",
      "amazon.titan-e1t-medium\n",
      "amazon.titan-embed-g1-text-02\n",
      "amazon.titan-text-lite-v1\n",
      "amazon.titan-text-express-v1\n",
      "amazon.titan-embed-text-v1\n",
      "stability.stable-diffusion-xl\n",
      "stability.stable-diffusion-xl-v0\n",
      "ai21.j2-grande-instruct\n",
      "ai21.j2-jumbo-instruct\n",
      "ai21.j2-mid\n",
      "ai21.j2-mid-v1\n",
      "ai21.j2-ultra\n",
      "ai21.j2-ultra-v1\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v1\n",
      "anthropic.claude-v2\n",
      "cohere.command-text-v14\n"
     ]
    }
   ],
   "source": [
    "# 利用可能なモデルの確認\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "for model in bedrock_client.list_foundation_models()[\"modelSummaries\"]:\n",
    "    print(model[\"modelId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af6f0e-0e06-450b-a273-1a3dfa2a3d3f",
   "metadata": {},
   "source": [
    "# Claudeの利用例\n",
    "- 公式のClaude Prompt Designガイド: https://docs.anthropic.com/claude/docs/introduction-to-prompt-design\n",
    "- 2023/11/14現在では、Claude Instant v1が東京リージョンで利用可能です。情報抽出・分類等であればぜひ東京リージョンのClaude Instant v1もご利用下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4120573c-e445-4652-90c0-0a7d9029e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "from botocore.session import Session\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ReadTimeoutError, ClientError\n",
    "from anthropic import Anthropic\n",
    "\n",
    "\n",
    "def generate_anthropic(text, model, region):\n",
    "    # Pricingは変更される可能性がありますので、公式の料金ページを正としてください。 https://aws.amazon.com/jp/bedrock/pricing/\n",
    "    if model == \"claude-v2\":\n",
    "        prompt_cost_per_token = 0.00001102\n",
    "        completion_cost_per_token = 0.00003268\n",
    "        model_id=\"anthropic.claude-v2\" \n",
    "    elif model == \"claude-v1\":\n",
    "        prompt_cost_per_token = 0.00001102\n",
    "        completion_cost_per_token = 0.00003268\n",
    "        model_id=\"anthropic.claude-v1\" \n",
    "    elif model == \"claude-instant-v1\":\n",
    "        prompt_cost_per_token = 0.00000163\n",
    "        completion_cost_per_token = 0.00000551\n",
    "        model_id=\"anthropic.claude-instant-v1\" \n",
    "    else:\n",
    "        raise Exception(\"this model name does not supported here: \" + model)\n",
    "\n",
    "    s = Session()\n",
    "    boto3_bedrock =  s.create_client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=region, \n",
    "        config=Config(connect_timeout=300, read_timeout=300, retries={'max_attempts': 1})\n",
    "    )\n",
    "\n",
    "    # Claudeでのプロンプトのフォーマットはこちらに。https://docs.anthropic.com/claude/docs/introduction-to-prompt-design#human--assistant-formatting\n",
    "    # Bedrockではフォーマットに従わない場合エラーが返される挙動になっていますのでご注意下さい。\n",
    "    prompt = f\"{text}\"\n",
    "    # パラメータの詳細はこちらに。https://docs.anthropic.com/claude/reference/complete_post\n",
    "    # 出力のトークン数の最大数はmax_tokens_to_sampleで変更できます。\n",
    "    # stop_sequencesには今回は</result>も含めています。\n",
    "    body = json.dumps({\"prompt\": prompt, \"max_tokens_to_sample\": 1000, \"temperature\": 0, \"stop_sequences\": [\"\\n\\nHuman\", \"</result>\"],\n",
    "})\n",
    "    modelId = model_id \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    response = None\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = boto3_bedrock.invoke_model(\n",
    "            body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "        )\n",
    "    except ReadTimeoutError as e:\n",
    "        raise Exception(\"Timeout occurred while accessing Bedrock. Please increase connect_timeout or read_timeout value in initializing boto3_bedrock.\")\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == 'ThrottlingException':\n",
    "            raise Exception(\"ThrottlingException occurred. Please note that 'Tokens processed per minute' on claude v2 is limited to 200,000. Ref: https://docs.aws.amazon.com/bedrock/latest/userguide/quotas.html\")\n",
    "        raise e\n",
    "    response_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    completion = response_body.get(\"completion\")\n",
    "    \n",
    "    print(completion)\n",
    "\n",
    "    # ここではClaudeを利用した際のtoken数、料金、レスポンスタイムを測定しています。\n",
    "\n",
    "    anthropic_client = Anthropic()\n",
    "    prompt_tokens = anthropic_client.count_tokens(prompt)\n",
    "    completion_tokens = anthropic_client.count_tokens(completion)\n",
    "\n",
    "    prompt_cost = prompt_cost_per_token * prompt_tokens\n",
    "    completion_cost = completion_cost_per_token * completion_tokens\n",
    "    total_cost = prompt_cost + completion_cost\n",
    "\n",
    "    print(f'prompt_tokens: {prompt_tokens:,}, completion_tokens: {completion_tokens:,}, prompt_cost: ${prompt_cost:.9f}, completion_cost: ${completion_cost:.9f}, total_cost: ${total_cost:.9f}')\n",
    "    print(f'response_time: {response_time:,.0f} ms\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4423c536-474a-4e97-928e-4bb7f6041cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "お客様は明日渋谷へ行く予定です。\n",
      "\n",
      "prompt_tokens: 324, completion_tokens: 21, prompt_cost: $0.003570480, completion_cost: $0.000686280, total_cost: $0.004256760\n",
      "response_time: 2,096 ms\n",
      "\n",
      "お客様は明日渋谷へ行かれると述べられています。\n",
      "\n",
      "prompt_tokens: 324, completion_tokens: 27, prompt_cost: $0.000528120, completion_cost: $0.000148770, total_cost: $0.000676890\n",
      "response_time: 694 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transcribed_text = \"\"\"\n",
    "営業：こんにちは\n",
    "顧客：こんにちは\n",
    "営業：明日はどこへ行くのですか？\n",
    "顧客：明日は渋谷へ行きます。\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\\n\\nHuman:\n",
    "営業と顧客の会話記録を<transcription></transcription>タグの中に記します。\n",
    "\n",
    "<transcription>\n",
    "{transcribed_text}\n",
    "</transcription>\n",
    "\n",
    "会話記録を参考にして、次にユーザーが取ろうとしている行動を<rule></rule>タグ内の条件に従って回答してください。\n",
    "\n",
    "<rule>\n",
    "- \"顧客\"が取ろうとしている行動を回答してください\n",
    "- 必ず<transcription></transcription>タグに囲まれた会話記録で述べられている内容から回答を考えてください\n",
    "- 顧客のことを指す際は\"お客様\"と呼んで下さい\n",
    "- 回答は<result></result>タグに含めて回答し、<result></result>タグの前後には何も文字を出力しないでください。\n",
    "</rule>\n",
    "\\n\\nAssistant:<result>\n",
    "\"\"\"\n",
    "# invoke_model()を呼び出す際に、stop_sequencesというパラメータを設定しているのですが、そこに\"</result>\"も含めているので、</result>の直前で回答は切られます。\n",
    "\n",
    "\n",
    "generate_anthropic(prompt, 'claude-v2', 'us-east-1') # 北部バージニアリージョンのclaude-v2はmax 100K tokensを処理できます\n",
    "generate_anthropic(prompt, 'claude-instant-v1', 'ap-northeast-1') # 東京リージョンのclaude-instant-v1はmax 18K tokensに制限されています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413843d7-5006-4e89-a714-0dcd9d31c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\": \"n\", \"2\": \"p\", \"3\": \"n\", \"5\": \"n\", \"6\": \"n\", \"7\": \"p\", \"8\": \"p\"}\n",
      "\n",
      "prompt_tokens: 357, completion_tokens: 43, prompt_cost: $0.003934140, completion_cost: $0.001405240, total_cost: $0.005339380\n",
      "response_time: 2,416 ms\n",
      "\n",
      "{\"1\": \"n\", \"2\": \"p\", \"3\": \"n\", \"5\": \"n\", \"6\": \"n\", \"7\": \"p\", \"8\": \"p\"}\n",
      "\n",
      "prompt_tokens: 357, completion_tokens: 43, prompt_cost: $0.000581910, completion_cost: $0.000236930, total_cost: $0.000818840\n",
      "response_time: 806 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\\n\\nHuman:\n",
    "以下の<comment></comment>で囲まれたコメントの感情を、<rule></rule>に従って分類してください。\n",
    "\n",
    "<comment>\n",
    "1. \"帰ったら宿題やらなきゃなあ…\"\n",
    "2. \"ここのラーメン超うまい\"\n",
    "3. \"購入して１年ちょっとで壊れてしまいました。残念です。\"\n",
    "5. \"使い方が理解できなかった\"\n",
    "6. \"精度が低く使いものにならない\"\n",
    "7. \"ぜひ今後も継続して利用したいです\"\n",
    "8. \"思ったより丈夫で軽かったので驚きました\"\n",
    "</comment>\n",
    "\n",
    "<rule>\n",
    "- 全てのコメントを「ネガティブ: n」「ポジティブ: p」のいずれかに感情分類してください。コメントのidに対してpかnを回答します\n",
    "- 結果についてはJSON形式で返してください。それ以外の文字列は返却しないでください。\n",
    "- JSONは<result></result>タグの中に、次のような形式で1行で出力してください。{\"1\": \"p\", \"2\": \"n\"}\n",
    "</rule>\n",
    "\n",
    "\\n\\nAssistant:<result>\n",
    "\"\"\"\n",
    "generate_anthropic(prompt, 'claude-v2', 'us-east-1') # 北部バージニアリージョンのclaude-v2はmax 100K tokensを処理できます\n",
    "generate_anthropic(prompt, 'claude-instant-v1', 'ap-northeast-1') # 東京リージョンのclaude-instant-v1はmax 18K tokensに制限されています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47ce40-9774-404f-8f5e-741727aa1e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodrock-test-1",
   "language": "python",
   "name": "bodrock-test-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
